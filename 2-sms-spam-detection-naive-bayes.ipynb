{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Naive Bayes algorithm for sms spam detection\n",
    "\n",
    "In this assigment, you will predict if a sms message is 'spam' or 'ham' (i.e. not 'spam') using the Bernoulli Naive Bayes *classifier*.\n",
    "\n",
    "The training data is from the UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection.  Please download the zip file before running the code below. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1:  Getting, understanding, and cleaning the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                        sms_message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the usual libraries\n",
    "import numpy as np \n",
    "import pandas as pd  # To read in the dataset we will use the Panda's library\n",
    "df = pd.read_table('SMSSpamCollection', sep = '\\t', header=None, names=['label', 'sms_message'])\n",
    "\n",
    "# Next we observe the first 5 rows of the data to ensure everything was read correctly\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocesssing\n",
    "It would be more convenient if the labels were binary instead of 'ham' and 'spam'.  This way our code can always work with numerical values instead of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                        sms_message\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label']=df.label.map({'spam':1, 'ham':0})\n",
    "df.head() # Again, lets observe the first 5 rows to make sure everything worked before we continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dcoument into training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of training examples:  4179\n",
      "The number of test exampels:  1393\n",
      "The first four labels\n",
      "872     0\n",
      "831     1\n",
      "1273    0\n",
      "3314    0\n",
      "Name: label, dtype: int64\n",
      "The first four sms messages\n",
      "872     Its going good...no problem..but still need li...\n",
      "831     U have a secret admirer. REVEAL who thinks U R...\n",
      "1273                                                Ok...\n",
      "3314    Huh... Hyde park not in mel ah, opps, got conf...\n",
      "Name: sms_message, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# This time we will use sklearn's method for seperating the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train_msgs, df_test_msgs, df_ytrain, df_ytest = train_test_split(df['sms_message'],df['label'], random_state=0)\n",
    "\n",
    "#Looking at the train/test split\n",
    "print(\"The number of training examples: \", df_train_msgs.shape[0])\n",
    "print(\"The number of test exampels: \", df_test_msgs.shape[0])\n",
    "\n",
    "print(\"The first four labels\")\n",
    "print(df_ytrain[0:4])\n",
    "\n",
    "print(\"The first four sms messages\")\n",
    "print(df_train_msgs[0:4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Creating the feature vector from the text (feature extraction)\n",
    "\n",
    "Each message will have its own feature vector.  For each message we will create its feature vector as we discussed in class; we will have a feature for every word in our vocabulary.  The $j$th feature is set to one ($x_j=1$) if the $j$th word from our vocabulary occurs in the message, and set the $j$ feature is set to $0$ otherwise ($x_j=0$).\n",
    "\n",
    "We will use the sklearn method CountVectorize to create the feature vectors for every messge.\n",
    "\n",
    "We could have written the code to do this directly by performing the following steps:\n",
    "* remove capitalization\n",
    "* remove punctuation \n",
    "* tokenize (i.e. split the document into individual words)\n",
    "* count frequencies of each token \n",
    "* remove 'stop words' (these are words that will not help us predict since they occur in most documents, e.g. 'a', 'and', 'the', 'him', 'is' ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
      "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "                ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
      "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "                tokenizer=None, vocabulary=None)\n"
     ]
    }
   ],
   "source": [
    "# importing the library\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# creating an instance of CountVectorizer\n",
    "\n",
    "# Note there are issues with the way CountVectorizer removes stop words.  To learn more: https://scikit-learn.org/stable/modules/feature_extraction.html#stop-words\n",
    "vectorizer = CountVectorizer(binary = True, stop_words='english')\n",
    "\n",
    "# If we wanted to perform Multnomial Naive Bayes, we would include the word counts and use the following code\n",
    "#vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# To see the 'count_vector' object\n",
    "print(vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see the 'stop words' \n",
    "# print(vectorizer.get_stop_words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label of the first training example:  0\n"
     ]
    }
   ],
   "source": [
    "# Create the vocabulary for our feature transformation\n",
    "vectorizer.fit(df_train_msgs)\n",
    "\n",
    "# Next we create the feature vectors for both the training data and the test data\n",
    "X_train = vectorizer.transform(df_train_msgs).toarray() # code to turn the training emails into a feature vector\n",
    "X_test = vectorizer.transform(df_test_msgs).toarray() # code to turn the test email into a feature vector\n",
    "\n",
    "# Changing the target vectors data type  \n",
    "y_train = df_ytrain.to_numpy() # Convereting from a Panda series to a numpy array\n",
    "y_test = df_ytest.to_numpy()\n",
    "\n",
    "# To observe what the data looks like \n",
    "print(\"The label of the first training example: \", y_train[0])\n",
    "#print(\"The first training example: \", X_train[0].tolist())# I needed to covernt the datatype to list so all the feature values would be printed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimated value for P(y) when y=0 and y=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(y=0) = 0.8655180665230916\n",
      "P(y=1) = 0.13448193347690834\n"
     ]
    }
   ],
   "source": [
    "# You should NOT use the features of sklearn library in your code.\n",
    "#### TO-DO #####\n",
    "def countbinary(arr):\n",
    "    binary, counts = np.unique(arr, return_counts=True)\n",
    "    return counts[0], counts[1], len(arr)\n",
    "\n",
    "countzero, countone, counttotal = countbinary(y_train)\n",
    "py0 = countzero/counttotal\n",
    "py1 = countone/counttotal\n",
    "print('P(y=0) =',py0)\n",
    "print('P(y=1) =',py1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Admirer when y=0 and y=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countattribute(attribute, arry, arrx):\n",
    "    index = vectorizer.vocabulary_[attribute]\n",
    "    attribute0, attribute1 = 0, 0\n",
    "    for i in range(len(arry)):\n",
    "        # given y is 0, count \n",
    "        if arry[i] == 0:\n",
    "            attribute0 += arrx[i][index]\n",
    "        else:\n",
    "            attribute1 += arrx[i][index]\n",
    "    countzero, countone, counttotal = countbinary(arry)\n",
    "    phi0 = attribute0/countzero\n",
    "    phi1 = attribute1/countone\n",
    "    return phi0, phi1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phi admirer|y=0 = 0.0\n",
      "phi admirer|y=1 = 0.014234875444839857\n"
     ]
    }
   ],
   "source": [
    "phi0, phi1 = countattribute('admirer', y_train, X_train)\n",
    "print('phi admirer|y=0 =',phi0)\n",
    "print('phi admirer|y=1 =',phi1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Secret when y=0 and y=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phi secret|y=0 = 0.000552944429084877\n",
      "phi secret|y=1 = 0.014234875444839857\n"
     ]
    }
   ],
   "source": [
    "phi0, phi1 = countattribute('secret', y_train, X_train)\n",
    "print('phi secret|y=0 =',phi0)\n",
    "print('phi secret|y=1 =',phi1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate φi|y for the Bernoulli corresponding to p(xi|y), for each attribute xi and each class y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham: [0.         0.         0.00027647 ... 0.00027647 0.         0.00027647]\n",
      "spam: [0.01245552 0.03558719 0.         ... 0.         0.00177936 0.        ]\n"
     ]
    }
   ],
   "source": [
    "ham = X_train[y_train == 0]\n",
    "spam = X_train[y_train == 1]\n",
    "phiham = np.sum(ham, axis=0)/countzero\n",
    "phispam = np.sum(spam, axis=0)/countone\n",
    "print('ham:', phiham)\n",
    "print('spam:', phispam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slower loop solution, no m smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = []\n",
    "for i in range(len(X_test)):\n",
    "    p_map0 = np.log(py0)\n",
    "    p_map1 = np.log(py1) \n",
    "    for j in range(len(X_test[0])):\n",
    "        if X_test[i][j] == 0:\n",
    "            p_map0 += np.log(1-phiham[j]) \n",
    "            p_map1 += np.log(1-phispam[j])\n",
    "        if X_test[i][j] == 1:\n",
    "            #if we encounter log(0), ignore\n",
    "            if phiham[j] > 0: \n",
    "                p_map0 +=  np.log(phiham[j]) \n",
    "            if phispam[j] > 0:\n",
    "                p_map1 += np.log(phispam[j])\n",
    "    predicted.append(0) if p_map0 > p_map1 else predicted.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy solution, with m smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def msmooth(num, denom):\n",
    "    m = 0.001\n",
    "    return (num+m)/(denom+m*2)\n",
    "\n",
    "mphiham = msmooth(ham.sum(axis=0), countzero) \n",
    "mphispam = msmooth(spam.sum(axis=0), countone)\n",
    "\n",
    "predicted_msmooth = []\n",
    "y0 = np.zeros(len(X_test)) + np.log(py0)\n",
    "y1 = np.zeros(len(X_test)) + np.log(py1)\n",
    "logphiham = np.where(mphiham > 0, np.log(mphiham), 0)\n",
    "logphispam = np.where(mphispam > 0, np.log(mphispam), 0)\n",
    "xy0 = np.where(X_test==1, logphiham, np.log(1-mphiham))\n",
    "xy1 = np.where(X_test==1, logphispam, np.log(1-mphispam))     \n",
    "y0 += np.sum(xy0, axis = 1)\n",
    "y1 += np.sum(xy1, axis = 1)\n",
    "predicted_msmooth = np.where(y0 > y1, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicted class, no m smoothing\n",
    "First 50 Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = np.array(predicted)\n",
    "predicted[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First 5 Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last 5 Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(arr1, arr2):\n",
    "    result = np.where(arr1==arr2, 1, 0)\n",
    "    return countbinary(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No m smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test examples classiﬁed correctly:  550\n",
      "Number of test examples classiﬁed incorrectly:  843\n",
      "Error Rate:  0.6051687006460876\n",
      "Accuracy Rate:  0.3948312993539124\n"
     ]
    }
   ],
   "source": [
    "countfalse, counttrue, counttotal = accuracy(predicted, y_test)\n",
    "print(\"Number of test examples classiﬁed correctly: \", counttrue)\n",
    "print(\"Number of test examples classiﬁed incorrectly: \", countfalse)\n",
    "print(\"Error Rate: \", countfalse/counttotal)\n",
    "print(\"Accuracy Rate: \", counttrue/counttotal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With m smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test examples classiﬁed correctly:  1377\n",
      "Number of test examples classiﬁed incorrectly:  16\n",
      "Error Rate:  0.01148600143575018\n",
      "Accuracy Rate:  0.9885139985642498\n"
     ]
    }
   ],
   "source": [
    "countfalse, counttrue, counttotal = accuracy(predicted_msmooth, y_test)\n",
    "print(\"Number of test examples classiﬁed correctly: \", counttrue)\n",
    "print(\"Number of test examples classiﬁed incorrectly: \", countfalse)\n",
    "print(\"Error Rate: \", countfalse/counttotal)\n",
    "print(\"Accuracy Rate: \", counttrue/counttotal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check with ML library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test examples classiﬁed correctly:  1377\n",
      "Number of test examples classiﬁed incorrectly:  16\n",
      "Error Rate:  0.01148600143575018\n",
      "Accuracy Rate:  0.9885139985642498\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "clf = BernoulliNB(alpha=0.001)\n",
    "clf.fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "countfalse, counttrue, counttotal = accuracy(predicted, y_test)\n",
    "print(\"Number of test examples classiﬁed correctly: \", counttrue)\n",
    "print(\"Number of test examples classiﬁed incorrectly: \", countfalse)\n",
    "print(\"Error Rate: \", countfalse/counttotal)\n",
    "print(\"Accuracy Rate: \", counttrue/counttotal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-R Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ham)>len(spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test examples classiﬁed correctly:  1208\n",
      "Number of test examples classiﬁed incorrectly:  185\n",
      "Error Rate:  0.13280689160086145\n",
      "Accuracy Rate:  0.8671931083991385\n"
     ]
    }
   ],
   "source": [
    "countfalse, counttrue, counttotal = accuracy(np.zeros(len(y_test)), y_test)\n",
    "print(\"Number of test examples classiﬁed correctly: \", counttrue)\n",
    "print(\"Number of test examples classiﬁed incorrectly: \", countfalse)\n",
    "print(\"Error Rate: \", countfalse/counttotal)\n",
    "print(\"Accuracy Rate: \", counttrue/counttotal)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
